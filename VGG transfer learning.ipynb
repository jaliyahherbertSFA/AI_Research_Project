{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24d157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, metrics\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Activation, MaxPool2D, BatchNormalization, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import sklearn.metrics as metrics\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f965627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import (vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba55243",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/jaliyah/data'\n",
    "biofilm_full_path = os.path.join(folder_path, 'biofilm')\n",
    "nonbio_full_path = os.path.join(folder_path, 'single_cell')\n",
    "my_bio_files_list = []\n",
    "my_non_files_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca77f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(biofilm_full_path):\n",
    "    my_bio_files_list.append(os.path.join(biofilm_full_path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fb4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88a7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "total_img_bio = np.zeros((276,img_width,img_height,3), dtype=np.int16)\n",
    "biofilm_label= np.ones(276)\n",
    "print(total_img_bio.shape)\n",
    "for (i,file) in enumerate(my_bio_files_list):\n",
    "    img = cv2.imread(file)\n",
    "   # print(file)\n",
    "   # plt.imshow(img)\n",
    "   # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    img_1 = img.resize(img_width,img_height,3)\n",
    "    total_img_bio[i] = img\n",
    "   # print(biofilm_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111892de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(nonbio_full_path):\n",
    "    my_non_files_list.append(os.path.join(nonbio_full_path,file))\n",
    "#print((my_non_files_list[63]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e213a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "total_img_non = np.zeros((190,img_width,img_height,3), dtype=np.int16)\n",
    "print(total_img_non.shape)\n",
    "non_biofilm_label= np.zeros(190)\n",
    "\n",
    "for (i,file) in enumerate(my_non_files_list):\n",
    "    img = cv2.imread(file)\n",
    "   # print(os.path.exists(file))\n",
    "    #print(file)\n",
    "    img_1 = img.resize(img_width,img_height,3)\n",
    "    #print(file)\n",
    "    #print (img.shape)\n",
    "    #print(img)\n",
    "    total_img_non[i] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3949d629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "total = total_img_bio.shape[0]\n",
    "size = int(total * .20)\n",
    "test_bio = random.sample(range(0, total), size)\n",
    "np.unique(test_bio).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7794636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bio_img = total_img_bio[test_bio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addd579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bio_lbl = biofilm_label[test_bio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17cd265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = total_img_non.shape[0]\n",
    "size = int(total * .20)\n",
    "test_non = random.sample(range(0, total), size)\n",
    "np.unique(test_non).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4435047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_non_img = total_img_non[test_non]\n",
    "test_non_lbl = non_biofilm_label[test_non]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ae4d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_img = np.concatenate([test_bio_img,test_non_img])\n",
    "total_test_lbl = np.concatenate([test_bio_lbl,test_non_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "727c5a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "a = list(range(total_img_bio.shape[0]))\n",
    "#gives us total 2225 to use for train/vali\n",
    "train_vali_total = (set(a) -(set(test_bio)))\n",
    "len_train_vali_total = (len(train_vali_total))\n",
    "print(len_train_vali_total)\n",
    "size = int(len_train_vali_total * .10)\n",
    "#size\n",
    "vail_bio = random.sample(range(0, len_train_vali_total), size)\n",
    "np.unique(vail_bio).shape\n",
    "vail_bio_img = total_img_bio[vail_bio]\n",
    "vail_bio_lbl = biofilm_label[vail_bio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c60761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199,)\n"
     ]
    }
   ],
   "source": [
    "a = list(range(len_train_vali_total))\n",
    "train_total = (set(a) -(set(vail_bio)))\n",
    "train_bio = list(train_total)\n",
    "train_bio_img = total_img_bio[train_bio]\n",
    "train_bio_lbl = biofilm_label[train_bio]\n",
    "train_bio_img.shape\n",
    "x = np.array(train_bio)\n",
    "print(np.unique(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9245adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "a = list(range(total_img_non.shape[0]))\n",
    "#gives us total 4897 to use for train/vali\n",
    "train_vali_non_total = (set(a) -(set(test_non)))\n",
    "len_train_vali_non_total = (len(train_vali_non_total))\n",
    "print(len_train_vali_non_total)\n",
    "size = int(len_train_vali_non_total * .10)\n",
    "print(size)\n",
    "vail_non = random.sample(range(0, len_train_vali_non_total), size)\n",
    "vail_non_img = total_img_non[vail_non]\n",
    "vail_non_lbl = non_biofilm_label[vail_non]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd2d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(len_train_vali_non_total))\n",
    "train_non_total = (set(a) -(set(vail_non)))\n",
    "train_non = list(train_non_total)\n",
    "train_non_img = total_img_non[train_non]\n",
    "train_non_lbl = non_biofilm_label[train_non]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927872f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vali_img = np.concatenate([vail_bio_img,vail_non_img])\n",
    "total_vali_lbl = np.concatenate([vail_bio_lbl,vail_non_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bab060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_img = np.concatenate([train_bio_img,train_non_img])\n",
    "total_train_lbl = np.concatenate([train_bio_lbl,train_non_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abb3eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 16:57:31.913753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:31.941955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:31.942204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:31.942926: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 16:57:31.946748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:31.947017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:31.947249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:32.337488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:32.337684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:32.337833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 16:57:32.337979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45794 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "vgg_model = vgg16.VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd588cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(vgg_model.layers[:-1])\n",
    "model.add(keras.layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc397e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model_clone = keras.models.clone_model(vgg_model)\n",
    "vgg_model_clone.set_weights(vgg_model.get_weights())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c7aa5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fe8485805b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fe8485804c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fe8485f9850>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fe84857a1c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fe84857aa30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fe84857ab80>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fe8484ff190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fe8484ff670>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_clone.layers[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b78224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "903b4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 16:57:48.767500: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "2022-08-01 16:57:49.766895: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-01 16:57:49.768947: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-08-01 16:57:49.768958: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-08-01 16:57:49.769015: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-08-01 16:57:50.469024: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 224ms/step - loss: 0.2650 - accuracy: 0.8988 - val_loss: 0.1222 - val_accuracy: 0.9730\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1906 - accuracy: 0.9345 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.1364 - accuracy: 0.9524 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 1s 92ms/step - loss: 0.0774 - accuracy: 0.9673 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 1,153,602\n",
      "Non-trainable params: 133,115,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[0:8]:\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[8:24]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-1:]:\n",
    "    layer.trainable = True\n",
    "#optimizer = keras.optimizers.SGD(lr=1e-4) # the default lr is 1e-3\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "history = model.fit(total_train_img, total_train_lbl, epochs=5,\n",
    " validation_data=(total_vali_img, total_vali_lbl))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7e86848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122926080068\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1087 - accuracy: 0.9570 - precision_1: 0.9322 - recall_1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10865256935358047, 0.9569892287254333, 0.9322034120559692, 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = 2 * (0.9322034120559692 * 1.0) / (0.9322034120559692 + 1.0)\n",
    "print(F1)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(total_test_img,total_test_lbl)\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fa30e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c251082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74136c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "192c040c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.6141 - precision_1: 0.5979 - recall_1: 0.9882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 17:00:18.799356: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24662507520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82667, saving model to saved_models/model_1.h5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5863 - accuracy: 0.6141 - precision_1: 0.5979 - recall_1: 0.9882 - val_loss: 0.3498 - val_accuracy: 0.8267 - val_precision_1: 0.7969 - val_recall_1: 1.0000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.9060 - precision_1: 0.8586 - recall_1: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 17:00:29.860673: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24662507520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82667 to 0.97333, saving model to saved_models/model_1.h5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3334 - accuracy: 0.9060 - precision_1: 0.8586 - recall_1: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9733 - val_precision_1: 1.0000 - val_recall_1: 0.9608\n",
      "Epoch 3/50\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2220 - accuracy: 0.9826 - precision_1: 0.9760 - recall_1: 0.9939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 17:00:40.806350: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24662507520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.97333\n",
      "10/10 [==============================] - 9s 922ms/step - loss: 0.2263 - accuracy: 0.9765 - precision_1: 0.9711 - recall_1: 0.9882 - val_loss: 0.2348 - val_accuracy: 0.9333 - val_precision_1: 0.9792 - val_recall_1: 0.9216\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9732 - precision_1: 0.9709 - recall_1: 0.9824\n",
      "Epoch 00004: val_accuracy did not improve from 0.97333\n",
      "10/10 [==============================] - 9s 943ms/step - loss: 0.1871 - accuracy: 0.9732 - precision_1: 0.9709 - recall_1: 0.9824 - val_loss: 0.1935 - val_accuracy: 0.9467 - val_precision_1: 1.0000 - val_recall_1: 0.9216\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9765 - precision_1: 0.9766 - recall_1: 0.9824\n",
      "Epoch 00005: val_accuracy did not improve from 0.97333\n",
      "10/10 [==============================] - 9s 945ms/step - loss: 0.1378 - accuracy: 0.9765 - precision_1: 0.9766 - recall_1: 0.9824 - val_loss: 0.1607 - val_accuracy: 0.9467 - val_precision_1: 0.9796 - val_recall_1: 0.9412\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9765 - precision_1: 0.9711 - recall_1: 0.9882\n",
      "Epoch 00006: val_accuracy did not improve from 0.97333\n",
      "10/10 [==============================] - 9s 937ms/step - loss: 0.1155 - accuracy: 0.9765 - precision_1: 0.9711 - recall_1: 0.9882 - val_loss: 0.1213 - val_accuracy: 0.9600 - val_precision_1: 1.0000 - val_recall_1: 0.9412\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9799 - precision_1: 0.9767 - recall_1: 0.9882"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m logdir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \n\u001b[1;32m     33\u001b[0m my_callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     35\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(logdir, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m                                 save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m ]\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/model_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold_var)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(valid_generator)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/keras/engine/training.py:1267\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m   val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1265\u001b[0m   epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1267\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1268\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/keras/callbacks.py:414\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    412\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 414\u001b[0m   \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/keras/callbacks.py:2468\u001b[0m, in \u001b[0;36mTensorBoard.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch_metrics(epoch, logs)\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2468\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2471\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_embeddings(epoch)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/keras/callbacks.py:2536\u001b[0m, in \u001b[0;36mTensorBoard._log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weight \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mweights:\n\u001b[1;32m   2535\u001b[0m   weight_name \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2536\u001b[0m   \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2537\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_images:\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_weight_as_image(weight, weight_name, epoch)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py:178\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    168\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy(),\n\u001b[1;32m    169\u001b[0m     (tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTPUStrategy, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mTPUStrategy),\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    172\u001b[0m         tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mshould_record_summaries(),\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtpu\u001b[38;5;241m.\u001b[39moutside_compilation(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    177\u001b[0m     )\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhistogram_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py:154\u001b[0m, in \u001b[0;36mhistogram.<locals>.histogram_summary\u001b[0;34m(data, buckets, histogram_metadata, step)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:771\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[1;32m    769\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 771\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_record_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary_cond\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    774\u001b[0m   ops\u001b[38;5;241m.\u001b[39madd_to_collection(ops\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39m_SUMMARY_COLLECTION, op)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py:57\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_value:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:759\u001b[0m, in \u001b[0;36mwrite.<locals>.record\u001b[0;34m()\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Note the identity to move the tensor to the CPU.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 759\u001b[0m   summary_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m callable(tensor) \u001b[38;5;28;01melse\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(\n\u001b[1;32m    760\u001b[0m       tensor)\n\u001b[1;32m    761\u001b[0m   write_summary_op \u001b[38;5;241m=\u001b[39m gen_summary_ops\u001b[38;5;241m.\u001b[39mwrite_summary(\n\u001b[1;32m    762\u001b[0m       _summary_state\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39m_resource,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    763\u001b[0m       step,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m       serialized_metadata,\n\u001b[1;32m    767\u001b[0m       name\u001b[38;5;241m=\u001b[39mscope)\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/util/lazy_tensor_creator.py:66\u001b[0m, in \u001b[0;36mLazyTensorCreator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m _CALL_IN_PROGRESS_SENTINEL\n\u001b[0;32m---> 66\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py:152\u001b[0m, in \u001b[0;36mhistogram.<locals>.histogram_summary.<locals>.lazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py:250\u001b[0m, in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    245\u001b[0m             a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([bucket_starts, bucket_ends, bucket_counts])\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(is_singular, when_singular, when_nonsingular)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_nonempty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1452\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m \n\u001b[1;32m   1385\u001b[0m \u001b[38;5;124;03m  `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:552\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    545\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    547\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    551\u001b[0m           instructions)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1262\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1259\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m-> 1262\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1151\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1151\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m   1153\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorboard/plugins/histogram/summary_v2.py:248\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m     bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    242\u001b[0m         [tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mdata), tf\u001b[38;5;241m.\u001b[39mfloat64)]\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    245\u001b[0m         a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([bucket_starts, bucket_ends, bucket_counts])\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_singular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_singular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_nonsingular\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1452\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m \n\u001b[1;32m   1385\u001b[0m \u001b[38;5;124;03m  `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:552\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    545\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    547\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    551\u001b[0m           instructions)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1262\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1259\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m-> 1262\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1151\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1151\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m   1153\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X =  np.concatenate([total_train_img,total_vali_img])\n",
    "y = np.concatenate([total_train_lbl,total_vali_lbl])\n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = 'saved_models/'\n",
    "fold_var = 1\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True) \n",
    "# enumerate splits\n",
    "for train_index, valid_index in kfold.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=32, shuffle=True)\n",
    "    valid_generator = train_datagen.flow(X_valid, y_valid, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model = keras.models.Sequential(vgg_model.layers[:-1])\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    for layer in model.layers[0:8]:\n",
    "        layer.trainable = True\n",
    "    for layer in model.layers[8:24]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-1:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "       optimizer=tf.optimizers.Adam(learning_rate=0.00001),  \n",
    "       metrics=['accuracy',tf.metrics.Precision(),tf.metrics.Recall()])\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))  \n",
    "    my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5),\n",
    "    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "                                    monitor='val_accuracy', verbose=1, \n",
    "                                    save_best_only=True, mode='max')\n",
    "    ]\n",
    "\n",
    "    model.fit(train_generator, validation_data=valid_generator,\n",
    "                callbacks=my_callbacks, epochs=50)\n",
    "    model.load_weights(\"saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "    results = model.evaluate(valid_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1b00531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7602 - accuracy: 0.4516 - precision: 0.5909 - recall: 0.2364\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow(total_test_img,total_test_lbl)\n",
    "loss, accuracy,Precision, Recall = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9507341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7498018026351929"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7ae6dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 block1_conv1 (None, 224, 224, 64)\n",
      "1 block1_conv2 (None, 224, 224, 64)\n",
      "3 block2_conv1 (None, 112, 112, 128)\n",
      "4 block2_conv2 (None, 112, 112, 128)\n",
      "6 block3_conv1 (None, 56, 56, 256)\n",
      "7 block3_conv2 (None, 56, 56, 256)\n",
      "8 block3_conv3 (None, 56, 56, 256)\n",
      "10 block4_conv1 (None, 28, 28, 512)\n",
      "11 block4_conv2 (None, 28, 28, 512)\n",
      "12 block4_conv3 (None, 28, 28, 512)\n",
      "14 block5_conv1 (None, 14, 14, 512)\n",
      "15 block5_conv2 (None, 14, 14, 512)\n",
      "16 block5_conv3 (None, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "# summarize feature map shapes\n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # summarize output shape\n",
    "    print(i, layer.name, layer.output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ad54ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 1,145,408\n",
      "Non-trainable params: 13,569,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ixs = [3, 7, 9, 13, 15]\n",
    "outputs = [model.layers[i+1].output for i in ixs]\n",
    "model1 = tf.keras.Model(inputs=model.inputs, outputs=outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c4968ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_dir = pathlib.Path('/home/jaliyah/data/single_cell//')\n",
    "img_path = os.path.join(test_dir, 'slide eleven (313).jpg')\n",
    "\n",
    "test_img = keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n",
    "img_array = keras.preprocessing.image.img_to_array(test_img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "print(img_array.shape)\n",
    "#len(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4081f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps = model1.predict(img_array)\n",
    "len(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b0988c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "square = 8\n",
    "\n",
    "f = plt.figure(figsize=(15,15))\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(np.squeeze(feature_maps[4])[:, :, ix-1])\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d375a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, biases = model.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "n_filters, ix = 6, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(f[:, :, j], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc99bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_dir = pathlib.Path('/home/jaliyah/data/single_cell//')\n",
    "img_path = os.path.join(test_dir, 'slide eleven (313).jpg')\n",
    "\n",
    "test_img = keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n",
    "img_array = keras.preprocessing.image.img_to_array(test_img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5befbd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 1,149,505\n",
      "Non-trainable params: 133,115,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4c0e6ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m last_conv_layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock2_conv2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mmake_gradcam_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_conv_layer_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36mmake_gradcam_heatmap\u001b[0;34m(img_array, model, last_conv_layer_name, pred_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(class_channel, last_conv_layer_output)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# This is a vector where each entry is the mean intensity of the gradient\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# over a specific feature map channel\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m pooled_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# We multiply each channel in the feature map array\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# by \"how important this channel is\" with regard to the top predicted class\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# then sum all the channels to obtain the heatmap class activation\u001b[39;00m\n\u001b[1;32m     38\u001b[0m last_conv_layer_output \u001b[38;5;241m=\u001b[39m last_conv_layer_output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/dipak/tf/tf/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "last_conv_layer_name = 'block2_conv2'\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d181e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4633bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
